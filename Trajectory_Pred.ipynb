{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n",
    "# from tensorflow.python.ops import math_ops\n",
    "import tensorflow.keras.backend as kb\n",
    "from load_data import Files_Load, Boxes, test_split_norm_abnorm, norm_train_max_min\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = 20\n",
    "startvid=0\n",
    "endvid=1\n",
    "\n",
    "train_file = \"/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Train_Box/\"\n",
    "test_file = \"/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/\"\n",
    "\n",
    "loc_files_train, loc_files_test, box_train_txt, box_test_txt = Files_Load(train_file, test_file)\n",
    "\n",
    "traindict = Boxes(loc_files_train, box_train_txt, frames, pad ='pre')\n",
    "testdict = Boxes(loc_files_test[startvid:endvid], box_test_txt[startvid:endvid], frames, pad ='pre')\n",
    "abnormal_dict, normal_dict = test_split_norm_abnorm(testdict)\n",
    "\n",
    "# Normilize data\n",
    "max1 = traindict['x_ppl_box'].max()\n",
    "min1 = traindict['x_ppl_box'].min()\n",
    "xx,yy = norm_train_max_min(data_dict = traindict, max1=max1,min1=min1)\n",
    "xx_norm,yy_norm = norm_train_max_min(data_dict = normal_dict, max1=max1,min1=min1)\n",
    "xx_abnorm,yy_abnorm = norm_train_max_min(data_dict = abnormal_dict, max1=max1,min1=min1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.test.is_gpu_available()\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[1],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5500)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Files_Load():\n",
    "    train_file = \"/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Train_Box/\"\n",
    "    test_file = \"/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/\"\n",
    "    box_train_txt = os.listdir(train_file)\n",
    "    box_train_txt.sort()\n",
    "    box_test_txt = os.listdir(test_file)\n",
    "    box_test_txt.sort()\n",
    "    \n",
    "    loc_files_train, loc_files_test = [], []\n",
    "    \n",
    "    for txt in box_train_txt:\n",
    "        loc_files_train.append(train_file + txt)\n",
    "    for txt in box_test_txt:\n",
    "        loc_files_test.append(test_file + txt)\n",
    "    \n",
    "    return loc_files_train, loc_files_test, box_train_txt, box_test_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Boxes(loc_files, txt_names, time_steps, pad ='pre'):\n",
    "    \"\"\"\n",
    "    loc_files: List that contains that has text files save\n",
    "    txt_names: Txt file names. For visualization process\n",
    "    time_step: Sequence length input\n",
    "    pad: inputs 'pre' or 'post'\n",
    "    \n",
    "    x_person_box: Has bounding box locations\n",
    "    y_person_box: Label for bounding box locations\n",
    "    frame_person_id: Contains frame Number and person_Id of entire sequence, \n",
    "                     Last element is prediction frame. For visulization process\n",
    "    video_file: Points to video file used. For visulization process\n",
    "    \"\"\"\n",
    "    \n",
    "    x_ppl_box, y_ppl_box, frame_ppl_id, video_file, abnormal = [], [], [], [],[]  #Has bounding box locations inside\n",
    "    \n",
    "    #For splitting process\n",
    "    split_train_test = 0\n",
    "    split = 0\n",
    "    find_split = 0\n",
    "    \n",
    "    # Tells me how many in sequence was short.\n",
    "    # Do I want to go back and count for train and test seperatly \n",
    "    short_len = 0\n",
    "    \n",
    "#     datadict = OrderedDict()\n",
    "    datadict = {}\n",
    "    \n",
    "    for loc, txt_name in zip(loc_files, txt_names):\n",
    "        data = pd.read_csv(loc, ' ' )\n",
    "        # Note that person_box is 1 behind ID\n",
    "        max_person = data['Person_ID'].max()\n",
    "        for num in range(1,max_person+1):\n",
    "            temp_box = data[data['Person_ID'] == num ]['BB_tl_0\tBB_tl_1\tBB_br_0\tBB_br_1'.split()].values\n",
    "            person_seq_len = len(temp_box)\n",
    "            temp_frame_id = data[data['Person_ID'] == num ]['Frame_Number Person_ID'.split()].values\n",
    "            abnormal_frame_ped = data[data['Person_ID'] == num]['anomaly'].values\n",
    "            if person_seq_len > time_steps:\n",
    "                for i in range(0, person_seq_len - time_steps):\n",
    "                    temp_person_box = temp_box[i:(i+time_steps)]\n",
    "                    temp_fr_person_id = temp_frame_id[i:(i+time_steps+1)]\n",
    "\n",
    "                    x_ppl_box.append(temp_person_box)\n",
    "                    y_ppl_box.append(temp_box[i+time_steps])\n",
    "                    \n",
    "                    assert temp_person_box.shape == (time_steps,4)\n",
    "                    assert temp_fr_person_id.shape  == (time_steps+1,2), print(temp_fr_person_id.shape)\n",
    "                    \n",
    "                    frame_ppl_id.append(temp_fr_person_id)\n",
    "                    \n",
    "                    video_file.append(txt_name)      \n",
    "                    abnormal.append(abnormal_frame_ped[i+time_steps]) #Finds if predicted frame is abnormal\n",
    "                    \n",
    "            elif person_seq_len == 1:\n",
    "                # want it to skip loop\n",
    "                continue\n",
    "            elif person_seq_len <= time_steps:\n",
    "                temp_person_box_unpad = temp_box\n",
    "                temp_fr_person_id_unpad = temp_frame_id\n",
    "                temp_person_box = pad_sequences(temp_person_box_unpad.T, maxlen = time_steps+1, padding = pad).T\n",
    "                temp_fr_person_id = pad_sequences(temp_fr_person_id_unpad.T,  maxlen = time_steps+1, padding = pad).T\n",
    "                \n",
    "                assert temp_person_box.shape == (time_steps+1,4)\n",
    "                assert temp_fr_person_id.shape  == (time_steps+1,2)\n",
    "                \n",
    "                x_ppl_box.append(temp_person_box[0:time_steps,:])\n",
    "                y_ppl_box.append(temp_person_box[time_steps,:])\n",
    "                \n",
    "                frame_ppl_id.append(temp_fr_person_id[0:time_steps+1,:])\n",
    "                \n",
    "                video_file.append(txt_name)\n",
    "                abnormal.append(abnormal_frame_ped[-1]) #Finds if predicted frame is abnormal\n",
    "\n",
    "            else:\n",
    "                print('error')\n",
    "#     np.random.seed(49)\n",
    "#     rand = np.random.permutation(len(x_ppl_box))\n",
    "#     datadict['x_ppl_box'] = np.array(x_ppl_box)[rand]\n",
    "#     datadict['y_ppl_box'] = np.array(y_ppl_box)[rand]\n",
    "#     datadict['frame_ppl_id'] = np.array(frame_ppl_id)[rand]\n",
    "#     datadict['video_file'] = np.array(video_file)[rand]\n",
    "#     datadict['abnormal'] = np.array(abnormal)[rand]\n",
    "\n",
    "    datadict['x_ppl_box'] = np.array(x_ppl_box)\n",
    "    datadict['y_ppl_box'] = np.array(y_ppl_box)\n",
    "    datadict['frame_ppl_id'] = np.array(frame_ppl_id)\n",
    "    datadict['video_file'] = np.array(video_file)\n",
    "    datadict['abnormal'] = np.array(abnormal)\n",
    "        \n",
    "    return  datadict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Plot Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(y, x):\n",
    "    xA = kb.max((x[:,0:1],y[:,0:1]), axis=0,keepdims=True)\n",
    "    yA = kb.max((x[:,1:2],y[:,1:2]), axis=0,keepdims=True)\n",
    "    xB = kb.min((x[:,2:3],y[:,2:3]), axis=0,keepdims=True)\n",
    "    yB = kb.min((x[:,3:4],y[:,3:4]), axis=0,keepdims=True)\n",
    "\n",
    "    interArea1 = kb.max((kb.zeros_like(xB), (xB-xA +1) ), axis=0, keepdims=True)\n",
    "    interArea2 = kb.max((kb.zeros_like(xB), (yB-yA +1) ), axis=0, keepdims=True)\n",
    "    interArea = interArea1*interArea2\n",
    "    boxAArea = (x[:,2:3] - x[:,0:1] + 1) * (x[:,3:4] - x[:,1:2] + 1)\n",
    "    boxBArea = (y[:,2:3] - y[:,0:1] + 1) * (y[:,3:4] - y[:,1:2] + 1)\n",
    "\n",
    "    iou = interArea / (boxAArea + boxBArea - interArea)\n",
    "    iou_mean = -kb.mean(iou)\n",
    "    return iou_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading with 20 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0685737133026123\n"
     ]
    }
   ],
   "source": [
    "loc_files_train, loc_files_test, box_train_txt, box_test_txt = Files_Load()\n",
    "start = time.time()\n",
    "# x_ppl_box, y_ppl_box, frame_ppl_id, video_file,trialdict = Boxes(loc_files_train, box_train_txt, 20, pad ='pre')\n",
    "traindict = Boxes(loc_files_train, box_train_txt, 20, pad ='pre')\n",
    "end = time.time()\n",
    "print(end -start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2543485164642334\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "testdict = Boxes(loc_files_test[0:1], box_test_txt[0:1], 20, pad ='pre')\n",
    "end = time.time()\n",
    "print(end -start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01.txt', '01.txt', '01.txt', ..., '16.txt', '16.txt', '16.txt'],\n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindict['video_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/01.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/02.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/03.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/04.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/05.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/06.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/07.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/08.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/09.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/10.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/11.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/12.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/13.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/14.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/15.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/16.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/17.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/18.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/19.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/20.txt',\n",
       " '/home/akanu/Dataset/Anomaly/Avenue_Dataset/bounding_box_tlbr/Txt_Data/Test_Box/21.txt']"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_files_test[0:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDict(frames =20, startvid=0,endvid=1 ):\n",
    "    loc_files_train, loc_files_test, box_train_txt, box_test_txt = Files_Load()\n",
    "    traindict = Boxes(loc_files_train, box_train_txt, frames, pad ='pre')\n",
    "    testdict = Boxes(loc_files_test[startvid:endvid], box_test_txt[startvid:endvid], frames, pad ='pre')\n",
    "    return traindict,testdict\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sepearate_norm_abnorm(testdict):\n",
    "    abnormal_index = np.nonzero(testdict['abnormal'])\n",
    "    normal_index = np.where(testdict['abnormal'] == 0)\n",
    "    normal_dict = {}\n",
    "    abnormal_dict = {}\n",
    "    \n",
    "    for key in testdict.keys():\n",
    "        normal_dict[key] = testdict[key][normal_index]\n",
    "        abnormal_dict[key] = testdict[key][abnormal_index]\n",
    "    \n",
    "\n",
    "    return abnormal_dict, normal_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_train_max_min(traindict = None, testdict = None, unnorm_data = None, unorm=False):\n",
    "    \n",
    "    max1 = traindict['x_ppl_box'].max()\n",
    "    min1 = traindict['x_ppl_box'].min()\n",
    "    if unorm:\n",
    "        data = unnorm_data*(max1-min1) + min1\n",
    "        return data\n",
    "    \n",
    "    else:\n",
    "        abnormal_dict, normal_dict = test_sepearate_norm_abnorm(testdict)\n",
    "\n",
    "        abnormal_test_x = abnormal_dict['x_ppl_box']\n",
    "        abnormal_test_y = abnormal_dict['y_ppl_box']\n",
    "        test_x = normal_dict['x_ppl_box']\n",
    "        test_y = normal_dict['y_ppl_box']\n",
    "\n",
    "\n",
    "        xx = (traindict['x_ppl_box'] - min1)/(max1 - min1)\n",
    "        xx_test_abnorm = (abnormal_test_x - min1)/(max1-min1)\n",
    "        xx_test_norm = (test_x - min1)/(max1-min1)\n",
    "        \n",
    "        yy = (traindict['y_ppl_box'] - min1)/(max1-min1)\n",
    "        yy_test_abnorm = (abnormal_test_y - min1)/(max1-min1)\n",
    "        yy_test_norm = (test_y - min1)/(max1-min1)\n",
    "        \n",
    "        return xx,yy, xx_test_abnorm, yy_test_abnorm, xx_test_norm, yy_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abnorm_dict,norm_dict = test_sepearate_norm_abnorm(testdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abnormal_test_x = abnormal_dict['x_ppl_box']\n",
    "# abnormal_test_y = abnormal_dict['y_ppl_box']\n",
    "# test_x = normal_dict['x_ppl_box']\n",
    "# test_y = normal_dict['y_ppl_box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx = (traindict['x_ppl_box'] - traindict['x_ppl_box'].mean())/traindict['x_ppl_box'].std()\n",
    "# xx_test_abnorm = (abnormal_test_x - traindict['x_ppl_box'].mean())/traindict['x_ppl_box'].std()\n",
    "# xx_test = (test_x - traindict['x_ppl_box'].mean())/traindict['x_ppl_box'].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yy = (traindict['y_ppl_box'] - traindict['x_ppl_box'].mean())/traindict['x_ppl_box'].std()\n",
    "# yy_test_abnorm = (abnormal_test_y - traindict['x_ppl_box'].mean())/traindict['x_ppl_box'].std()\n",
    "# yy_test = (test_y - traindict['x_ppl_box'].mean())/traindict['x_ppl_box'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max1 = traindict['x_ppl_box'].max()\n",
    "# min1 = traindict['x_ppl_box'].min()\n",
    "# xx = (traindict['x_ppl_box'] - min1)/(max1 - min1)\n",
    "# xx_test_abnorm = (abnormal_test_x - min1)/(max1-min1)\n",
    "# xx_test = (test_x - min1)/(max1-min1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yy = (traindict['y_ppl_box'] - min1)/(max1-min1)\n",
    "# yy_test_abnorm = (abnormal_test_y - min1)/(max1-min1)\n",
    "# yy_test = (test_y - min1)/(max1-min1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindict,testdict = getDict()\n",
    "xx,yy, xx_test_abnorm, yy_test_abnorm, xx_test_norm, yy_test_norm = normalize_train_max_min(traindict=traindict, testdict=testdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7958993476234856\n",
      "-0.022367194780987885\n",
      "0.739049394221808\n",
      "0.1342031686859273\n"
     ]
    }
   ],
   "source": [
    "print(yy_test.max())\n",
    "print(yy_test.min())\n",
    "print(yy_test_abnorm.max())\n",
    "print(yy_test_abnorm.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 20, 4)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_train_max_min(traindict=traindict,unnorm_data=xx_test_abnorm,unorm=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 32\n",
    "xx_train, xx_val,yy_train,yy_val = train_test_split(xx,yy, test_size = 0.1)\n",
    "train_univariate = tf.data.Dataset.from_tensor_slices((xx_train,yy_train))\n",
    "train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "val_univariate = tf.data.Dataset.from_tensor_slices((xx_val,yy_val))\n",
    "val_univariate = val_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files Loaded with 5 Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc_files_train, loc_files_test, box_train_txt, box_test_txt = Files_Load()\n",
    "# start = time.time()\n",
    "# x_ppl_box_5, y_ppl_box_5, frame_ppl_id_5, video_file_5 = Boxes(loc_files_train, box_train_txt, 5, pad ='pre')\n",
    "# end = time.time()\n",
    "# print(end -start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# x_ppl_box_test_5, y_ppl_box_test_5, frame_ppl_id_test_5, video_file_test_5 = Boxes(loc_files_test, box_test_txt, 5, pad ='pre')\n",
    "# end = time.time()\n",
    "# print(end -start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx_5 = (x_ppl_box_5 - x_ppl_box_5.mean())/x_ppl_box_5.std()\n",
    "# xx_test_5 = (x_ppl_box_test_5 - x_ppl_box_test_5.mean())/x_ppl_box_test_5.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yy_5 = (y_ppl_box_5 - x_ppl_box_5.mean())/x_ppl_box_5.std()\n",
    "# yy_test_5 = (y_ppl_box_test_5 - x_ppl_box_5.mean())/x_ppl_box_5.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# LSTM 20 Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3902/3902 [==============================] - 91s 23ms/step - loss: -0.4045 - mse: 0.0979 - val_loss: -0.5305 - val_mse: 0.0551\n",
      "Epoch 2/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.6095 - mse: 0.0386 - val_loss: -0.6762 - val_mse: 0.0312\n",
      "Epoch 3/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.7006 - mse: 0.0268 - val_loss: -0.7166 - val_mse: 0.0226\n",
      "Epoch 4/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.7294 - mse: 0.0188 - val_loss: -0.7395 - val_mse: 0.0154\n",
      "Epoch 5/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.7601 - mse: 0.0116 - val_loss: -0.7891 - val_mse: 0.0087\n",
      "Epoch 6/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.8071 - mse: 0.0078 - val_loss: -0.8186 - val_mse: 0.0071\n",
      "Epoch 7/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.8320 - mse: 0.0062 - val_loss: -0.8434 - val_mse: 0.0055\n",
      "Epoch 8/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.8585 - mse: 0.0046 - val_loss: -0.8714 - val_mse: 0.0038\n",
      "Epoch 9/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.8875 - mse: 0.0027 - val_loss: -0.9036 - val_mse: 0.0017\n",
      "Epoch 10/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9234 - mse: 0.0011 - val_loss: -0.9340 - val_mse: 9.0954e-04\n",
      "Epoch 11/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9372 - mse: 7.9255e-04 - val_loss: -0.9378 - val_mse: 8.2917e-04\n",
      "Epoch 12/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9400 - mse: 7.4138e-04 - val_loss: -0.9398 - val_mse: 8.0082e-04\n",
      "Epoch 13/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9417 - mse: 7.1262e-04 - val_loss: -0.9414 - val_mse: 7.7286e-04\n",
      "Epoch 14/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9430 - mse: 6.9355e-04 - val_loss: -0.9424 - val_mse: 7.6316e-04\n",
      "Epoch 15/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9439 - mse: 6.8026e-04 - val_loss: -0.9433 - val_mse: 7.4903e-04\n",
      "Epoch 16/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9447 - mse: 6.7027e-04 - val_loss: -0.9440 - val_mse: 7.4060e-04\n",
      "Epoch 17/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9453 - mse: 6.6218e-04 - val_loss: -0.9445 - val_mse: 7.3523e-04\n",
      "Epoch 18/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9458 - mse: 6.5569e-04 - val_loss: -0.9448 - val_mse: 7.3042e-04\n",
      "Epoch 19/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9462 - mse: 6.5023e-04 - val_loss: -0.9454 - val_mse: 7.2458e-04\n",
      "Epoch 20/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9466 - mse: 6.4534e-04 - val_loss: -0.9457 - val_mse: 7.2029e-04\n",
      "Epoch 21/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9469 - mse: 6.4111e-04 - val_loss: -0.9460 - val_mse: 7.1615e-04\n",
      "Epoch 22/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9472 - mse: 6.3722e-04 - val_loss: -0.9463 - val_mse: 7.1332e-04\n",
      "Epoch 23/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9475 - mse: 6.3350e-04 - val_loss: -0.9466 - val_mse: 7.1013e-04\n",
      "Epoch 24/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9477 - mse: 6.3013e-04 - val_loss: -0.9468 - val_mse: 7.0645e-04\n",
      "Epoch 25/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9479 - mse: 6.2704e-04 - val_loss: -0.9468 - val_mse: 7.0643e-04\n",
      "Epoch 26/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9482 - mse: 6.2400e-04 - val_loss: -0.9472 - val_mse: 7.0072e-04\n",
      "Epoch 27/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9484 - mse: 6.2083e-04 - val_loss: -0.9475 - val_mse: 6.9757e-04\n",
      "Epoch 28/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9486 - mse: 6.1791e-04 - val_loss: -0.9476 - val_mse: 6.9585e-04\n",
      "Epoch 29/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9488 - mse: 6.1523e-04 - val_loss: -0.9478 - val_mse: 6.9330e-04\n",
      "Epoch 30/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9489 - mse: 6.1278e-04 - val_loss: -0.9480 - val_mse: 6.9059e-04\n",
      "Epoch 31/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9491 - mse: 6.1014e-04 - val_loss: -0.9481 - val_mse: 6.8784e-04\n",
      "Epoch 32/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9493 - mse: 6.0754e-04 - val_loss: -0.9484 - val_mse: 6.8532e-04\n",
      "Epoch 33/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9495 - mse: 6.0527e-04 - val_loss: -0.9485 - val_mse: 6.8380e-04\n",
      "Epoch 34/100\n",
      "3902/3902 [==============================] - 88s 23ms/step - loss: -0.9496 - mse: 6.0291e-04 - val_loss: -0.9486 - val_mse: 6.8060e-04\n",
      "Epoch 35/100\n",
      "3902/3902 [==============================] - 88s 23ms/step - loss: -0.9498 - mse: 6.0049e-04 - val_loss: -0.9489 - val_mse: 6.7841e-04\n",
      "Epoch 36/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9499 - mse: 5.9841e-04 - val_loss: -0.9490 - val_mse: 6.7580e-04\n",
      "Epoch 37/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9501 - mse: 5.9617e-04 - val_loss: -0.9492 - val_mse: 6.7349e-04\n",
      "Epoch 38/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9502 - mse: 5.9397e-04 - val_loss: -0.9493 - val_mse: 6.7128e-04\n",
      "Epoch 39/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9504 - mse: 5.9209e-04 - val_loss: -0.9495 - val_mse: 6.6894e-04\n",
      "Epoch 40/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9505 - mse: 5.9013e-04 - val_loss: -0.9495 - val_mse: 6.6700e-04\n",
      "Epoch 41/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9506 - mse: 5.8818e-04 - val_loss: -0.9497 - val_mse: 6.6452e-04\n",
      "Epoch 42/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9508 - mse: 5.8616e-04 - val_loss: -0.9499 - val_mse: 6.6314e-04\n",
      "Epoch 43/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9509 - mse: 5.8451e-04 - val_loss: -0.9499 - val_mse: 6.6109e-04\n",
      "Epoch 44/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9510 - mse: 5.8260e-04 - val_loss: -0.9501 - val_mse: 6.5943e-04\n",
      "Epoch 45/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9511 - mse: 5.8084e-04 - val_loss: -0.9502 - val_mse: 6.5704e-04\n",
      "Epoch 46/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9513 - mse: 5.7894e-04 - val_loss: -0.9504 - val_mse: 6.5623e-04\n",
      "Epoch 47/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9514 - mse: 5.7728e-04 - val_loss: -0.9503 - val_mse: 6.5631e-04\n",
      "Epoch 48/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9515 - mse: 5.7578e-04 - val_loss: -0.9506 - val_mse: 6.5271e-04\n",
      "Epoch 49/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9516 - mse: 5.7406e-04 - val_loss: -0.9507 - val_mse: 6.5078e-04\n",
      "Epoch 50/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9517 - mse: 5.7230e-04 - val_loss: -0.9507 - val_mse: 6.4806e-04\n",
      "Epoch 51/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9518 - mse: 5.7080e-04 - val_loss: -0.9509 - val_mse: 6.4707e-04\n",
      "Epoch 52/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9519 - mse: 5.6922e-04 - val_loss: -0.9509 - val_mse: 6.4748e-04\n",
      "Epoch 53/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9520 - mse: 5.6743e-04 - val_loss: -0.9510 - val_mse: 6.4341e-04\n",
      "Epoch 54/100\n",
      "3902/3902 [==============================] - 89s 23ms/step - loss: -0.9521 - mse: 5.6616e-04 - val_loss: -0.9512 - val_mse: 6.4168e-04\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "    lstm_20 = keras.Sequential()\n",
    "    lstm_20.add(keras.layers.InputLayer(input_shape=xx.shape[-2:]))\n",
    "    lstm_20.add(keras.layers.LSTM(4,return_sequences =True ))\n",
    "    lstm_20.add(keras.layers.LSTM(3,return_sequences =True ))\n",
    "    lstm_20.add(keras.layers.LSTM(6,return_sequences =True ))\n",
    "    lstm_20.add(keras.layers.LSTM(4,return_sequences =True ))\n",
    "    lstm_20.add(keras.layers.LSTM(4,return_sequences =True ))\n",
    "    lstm_20.add(keras.layers.LSTM(4) )\n",
    "    lstm_20.add(keras.layers.Dense(4) )\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=8.726e-06)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(\"lstm_5_arc_model.h5\", \n",
    "                                                       save_best_only = True)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0005, patience=5)\n",
    "    lstm_20.compile(optimizer=opt, loss=bb_intersection_over_union, metrics='mse')\n",
    "    \n",
    "    lstm_20_history_1= lstm_20.fit(train_univariate,\n",
    "                               validation_data = val_univariate,\n",
    "                               epochs=100, \n",
    "                               callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 20, 4)             144       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20, 3)             96        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20, 6)             240       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 20, 4)             176       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 20, 4)             144       \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 4)                 144       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 964\n",
      "Trainable params: 964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_20.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3863308 , 0.2545565 , 0.42001975, 0.35493624]], dtype=float32)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_20.predict(xx_test_abnorm[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "l =[]\n",
    "for los,val in zip(lstm_20_history_1.history['loss'], lstm_20_history_1.history['val_loss']):\n",
    "    l.append(np.array([los -val ]))\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f64c833b080>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LSTM, 20 Frames')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i =10\n",
    "j=20\n",
    "plt.plot(np.arange(i,j), lstm_20_history_1.history['loss'][i:j],'b+', label='loss')\n",
    "plt.plot(np.arange(i,j), lstm_20_history_1.history['val_loss'][i:j],'r-+', label='val loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('LSTM, 20 Frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 10ms/step - loss: -0.8018 - mse: 0.0063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.8018190264701843, 0.006331674288958311]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_20.evaluate(xx_test_abnorm,yy_test_abnorm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iou metric. Should probably scale back to normal. Might not matter if not scaled back to normal\n",
    "class IouMetric(keras.metrics.Metric):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.iou_avg = self.add_weight(\"iou_avg\", initializer=\"zeros\")\n",
    "        self.bb_intersection_over_union = iou_function()\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true,y_pred):\n",
    "        print('Here1')\n",
    "        y_true = math_ops.cast(y_true, tf.float32)\n",
    "        y_pred = math_ops.cast(y_pred, tf.float32)\n",
    "        print('here')\n",
    "        iou_calc =  self.bb_intersection_over_union(y_true,y_pred)\n",
    "        self.iou_avg.assign_add(iou_calc)\n",
    "        self.count.assign_add(1)\n",
    "    def result(self):\n",
    "        return self.iou_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_actual,y_pred):\n",
    "#     print(y_actual)\n",
    "    kb.print_tensor(y_actual.shape)\n",
    "    kb.print_tensor(y_pred)\n",
    "    custom_loss=kb.square(y_actual-y_pred)\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0000005\n",
    "dense_model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=xx.shape[-2:]),\n",
    "    keras.layers.Dense(4)\n",
    "])\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "dense_model.compile(loss=\"mse\", optimizer=opt, metrics=bb_intersection_over_union)\n",
    "# dense_model.compile(loss=custom_loss, optimizer=opt)\n",
    "dense_model.compile(loss=bb_intersection_over_union, optimizer=opt, metrics = bb_intersection_over_union)\n",
    "\n",
    "# history1 = dense_model.fit(xx, yy,validation_split=.1, \n",
    "#                     epochs=15)\n",
    "# dense_history = dense_model.fit(train_univariate, epochs=5, validation_data =val_univariate  )\n",
    "dense_history = dense_model.fit(xx,yy, epochs=6 )\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model.evaluate(xx_test,yy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model.evaluate(xx_test_abnorm,yy_test_abnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_ppl_box.shape)\n",
    "print(yy[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,51), dense_history.history['loss'],'b+', label='loss')\n",
    "plt.plot(np.arange(1,51),dense_history.history['val_loss'], 'r+', label ='val loss')\n",
    "plt.legend()\n",
    "plt.title('Baseline Dense Network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,7), dense_history.history['loss'],'b+', label='loss')\n",
    "plt.plot(np.arange(1,7), dense_history.history['val_loss'], 'r+', label ='val loss')\n",
    "plt.legend()\n",
    "plt.title('Baseline Dense Network Data Shuffled, lr = {}'.format(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dense_history.history['loss'][30:51])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videoPlot(y_ppl_box,y_pred, frame_ppl_id, video_file, vid_type ='test'):\n",
    "    \"\"\"\n",
    "    Function is plotting the ground truth and predicted \n",
    "    \n",
    "    y_ppl_box: Actual Label for bounding box locations\n",
    "    y_ppl_box_pred: Prediction from Model of bounding box locations\n",
    "    frame_person_id: Contains frame Number and person_Id of entire sequence, \n",
    "                     Last element is prediction frame. For visulization process\n",
    "    video_file: Points to video file used. For visulization process\n",
    "    \"\"\"\n",
    "    # Need a way to save images\n",
    "    file = {}\n",
    "    file['train'] = '/home/akanu/Dataset/Anomaly/Avenue_Dataset/training_videos/'\n",
    "    file['test'] = \"/home/akanu/Dataset/Anomaly/Avenue_Dataset/testing_videos/\"\n",
    "    loc_videos = file[vid_type] + video_file[:2] + '.avi'\n",
    "    ###\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(loc_videos)\n",
    "    \n",
    "#     for i in range(-1, frame_ppl_id[0,-1,0] + 1):\n",
    "        #Assune sequences are connected and don't skip cuz of occlusions \n",
    "    for i in range(0,frame_ppl_id[0,-1,0]+1):\n",
    "        print(i)\n",
    "        ret, frame = video_capture.read()\n",
    "        if i == frame_ppl_id[0,-1,0]:\n",
    "            vid = int(video_file[:2])\n",
    "            pred_frame = frame.copy()\n",
    "            cv2.rectangle(frame, (int(y_ppl_box[0,0]), int(y_ppl_box[0,1])), (int(y_ppl_box[0,2]), int(y_ppl_box[0,3])),(255,255,255), 2)\n",
    "            cv2.putText(frame, str(frame_ppl_id[0,-1,1]),(int(y_ppl_box[0,0]), int(y_ppl_box[0,1])),0, 5e-3 * 200, (0,255,0),2)\n",
    "\n",
    "            cv2.rectangle(pred_frame, (int(y_pred[0,0]), int(y_pred[0,1])), (int(y_pred[0,2]), int(y_pred[0,3])),(255,255,0), 2)\n",
    "            cv2.putText(pred_frame, str(frame_ppl_id[0,-1,1]),(int(y_pred[0,0]), int(y_pred[0,1])),0, 5e-3 * 200, (0,255,0),2)\n",
    "            \n",
    "            cv2.imwrite('/home/akanu/git/deep_sort_yolov3/Images_saved/{:02d}_{:02d}_pred.jpg'.format(vid,i), pred_frame)\n",
    "            cv2.imwrite(\"/home/akanu/git/deep_sort_yolov3/Images_saved/{:02d}_{:02d}_gt.jpg\".format(vid,i), frame)\n",
    "            \n",
    "            print('saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/akanu/git/deep_sort_yolov3/Images_saved/01_20_900_pred.jpg'"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/home/akanu/git/deep_sort_yolov3/Images_saved/{:02d}_{:02d}_{:02d}_pred.jpg'.format(1,20,900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_videos(model,traindict,testdict):\n",
    "    #Might need to go back and make normalize function more robust\n",
    "    xx,yy, xx_test_abnorm, yy_test_abnorm, xx_test_norm, yy_test_norm = normalize_train_max_min(traindict=traindict, testdict=testdict)\n",
    "    abnormal_dict, normal_dict = test_sepearate_norm_abnorm(testdict)\n",
    "\n",
    "    \n",
    "    vid_file,frame_ppl= abnorm_dict['video_file'], abnorm_dict['frame_ppl_id']\n",
    "    y = abnorm_dict['y_ppl_box'] # not normailized\n",
    "    \n",
    "    for x,y_actual,frame_ppl_id, video_file,  in zip(xx_test_abnorm,y,frame_ppl,vid_file  ):  \n",
    "        \n",
    "        y_actual = np.expand_dims(y_actual,axis=0)\n",
    "        frame_ppl_id =np.expand_dims(frame_ppl_id, axis=0)\n",
    "        print(x)\n",
    "        print(\" {}  {} {}\".format(y_actual, frame_ppl_id, frame_ppl_id[0,-1,0]))\n",
    "        x = np.expand_dims(x,axis=0)\n",
    "        y_pred = model.predict(x)\n",
    "        y_pred = normalize_train_max_min(traindict=traindict, unnorm_data=y_pred, unorm=True)\n",
    "\n",
    "        # if x,y,c,h change to right coordinates\n",
    "        videoPlot(y_actual,y_pred, frame_ppl_id, video_file, vid_type ='test')\n",
    "#         print(y_actual)\n",
    "#         print(y_pred)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy_test_abnorm[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 3s 12ms/step - loss: 0.0000e+00 - mse: 104943.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 104943.765625]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_20.evaluate(testdict['x_ppl_box'],testdict['y_ppl_box'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
